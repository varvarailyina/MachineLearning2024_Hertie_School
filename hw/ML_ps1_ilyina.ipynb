{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7c91c1-db98-4ee1-b5ac-dc677b0571ee",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "***\n",
    "#### Problem Set 1\n",
    "#### Varvara Ilyina\n",
    "#### 2024-02-28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a54101-3c27-4ad0-9d5a-5cdceeb83381",
   "metadata": {},
   "source": [
    "The following exercises have been solved with the help of Chapters 1, 4 and 5 in _Probabilistic Machine Learning: An Introduction_ by Kevin Murphy.'', as well as some explanatory YouTube videos. Additionally, various internet resources and ChatGPT were used to aid me in generating the correct commands for my Python code.\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbeeb2-95f2-4777-a1c1-d62380cae7aa",
   "metadata": {},
   "source": [
    "##### 1. The particular task we will be considering is predicting `vote` based on five features: `TVnews`, `PID`, `age`, `educ`, and `popul`. Calculate summary statistics for the label and five features described above. Pay attention to the meaning of each variable and present a summary of it that makes sense given how it is coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5637a7d-8d56-4048-bbcc-701f33a82675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(944, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load packages\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# load dataset\n",
    "data = sm.datasets.anes96.load_pandas().data\n",
    "\n",
    "# extract necessary columns\n",
    "features = ['TVnews', 'PID', 'age', 'educ', 'popul']\n",
    "label = 'vote'\n",
    "df = data[features + [label]]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061fb4b4-6889-4494-98ee-b28183b69edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.10158756592995671\n"
     ]
    }
   ],
   "source": [
    "# split data into training and testing sets\n",
    "X = df[features]\n",
    "y = df[label]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d23c59cc-6af7-4091-aa07-530d22918749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TVnews         PID         age        educ        popul        vote\n",
      "count  944.000000  944.000000  944.000000  944.000000   944.000000  944.000000\n",
      "mean     3.727754    2.842161   47.043432    4.565678   306.381356    0.416314\n",
      "std      2.677235    2.273337   16.423130    1.599287  1082.606745    0.493208\n",
      "min      0.000000    0.000000   19.000000    1.000000     0.000000    0.000000\n",
      "25%      1.000000    1.000000   34.000000    3.000000     1.000000    0.000000\n",
      "50%      3.000000    2.000000   44.000000    4.000000    22.000000    0.000000\n",
      "75%      7.000000    5.000000   58.000000    6.000000   110.000000    1.000000\n",
      "max      7.000000    6.000000   91.000000    7.000000  7300.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "# print summary statistics\n",
    "summary = df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15135f53-ebe3-478b-8387-c401aad088d3",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbec7c-925e-4933-b59e-8b3de3a41a82",
   "metadata": {},
   "source": [
    "##### 2. What is the formula for the closed form estimate of the coefficient vector in ordinary least squares regression? Estimate the coefficients using numpy in Python by performing the matrix operations from the closed form solution we worked out in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d22b7-2851-448f-85ee-ff5679f820d5",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a34a90-f0fb-478c-8b8b-a321aaaad1ca",
   "metadata": {},
   "source": [
    "__Solution:__ \\\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7fdc5-b66f-4b32-9b16-b45f887f02d0",
   "metadata": {},
   "source": [
    "##### 3. Estimate the coefficients using the statsmodels package (sm.OLS documentation). Compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a1a10b-4be7-4e11-a3e9-808c3d22e3fe",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc149fb-b286-4f22-8b99-ecdf443a4876",
   "metadata": {},
   "source": [
    "__Solution:__ \\\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441b84d-c640-474b-a326-a38fe090ff6c",
   "metadata": {},
   "source": [
    "##### 4. Now, think about the model you just estimated. In class, we talked about two assumptions we could use to motivate estimation of the variance of this coefficient vector. Which would you choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44d9bc-8e48-4844-aec4-fb8d6d231f9a",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fa4e3-417c-465c-800a-d920f1786faf",
   "metadata": {},
   "source": [
    "__Solution:__ \\\n",
    "``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db81a40-9626-4f3c-abfe-03747dfa8c1c",
   "metadata": {},
   "source": [
    "##### 5. Estimate the variance of these coefficients using the matrix formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc154e-28d5-4bb3-b241-9fa16d87f312",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68887f16-e4c1-477b-8c75-9e757d4a6d72",
   "metadata": {},
   "source": [
    "##### 6. Create a table showing, for each feature, _j_, the estimate ($\\hat{β}$<sub>j</sub>), the standard error $\\sqrt{\\hat{Var}(\\hat{β})}$<sub>jj</sub>, and the upper and lower bounds of the 95% confidence interval ($\\hat{β}$<sub>j</sub> $± z$<sub>$\\alpha$</sub>$\\sqrt{\\hat{Var}(\\hat{β})}$<sub>jj</sub>). Compare the variance to what you got from statsmodels. What assumption are they using on the variance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd706caa-3bdc-40df-ab5b-cbedc799e3cb",
   "metadata": {},
   "source": [
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69a1d8-1e5c-4466-840c-f059b43b9cfd",
   "metadata": {},
   "source": [
    "##### 7. Write a function with three arguments:\n",
    "* `beta`: A 1D numpy array representing a particular value of your coefficients, $β$.\n",
    "* `label`: A 1D numpy array of the labels in your dataset.\n",
    "* `features`: A 2D numpy array representing the features in your dataset.\n",
    "##### This function should output a single number, the negative log-likelihood evaluated at the chosen value of $β$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e10294-059b-4e5b-b4bf-1de32e88a144",
   "metadata": {},
   "source": [
    "##### 8. Using the `SciPy` library, minimize the objective function we discussed in class for logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795ec67-cb79-4b9f-a6f2-7e75718717df",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_result = scipy.optimize.minimize(\n",
    "nll, args=(X, y), x0 = [0] * 6, method='BFGS'\n",
    ")\n",
    "beta_logistic = opt_result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d86cfa-c124-4e13-87d9-9e887fa6a5b3",
   "metadata": {},
   "source": [
    "##### 9. Now you can construct your predictions by taking the dot-product between beta logistic and your feature matrix and then passing that dot-product through the sigmoid function. This provides an estimate of the probability of class membership. Also calculate the most likely class for each unit by predicting a 1 when $p(y$<sub>i</sub>$|x$<sub>i</sub>$; β) > 0.5$ (i.e. the Heaviside function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d30d03-d3ed-48c2-a5b3-65b9a4220a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7277f3d1-e873-42c4-b31c-8b65dcabd490",
   "metadata": {},
   "source": [
    "##### 10. Construct class estimates for your OLS predictions as well by calculating $1(Xβ$<sub>ols</sub>$ > 0.5)$ (i.e. output a $1$ if the OLS predicted value is greater than $0.5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb68d86-93e3-40b8-8db2-9ea4645ce725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486121d4-9987-439a-a6f0-0b805839e0a2",
   "metadata": {},
   "source": [
    "##### 11. Calculate the full confusion matrix for the logistic regression and the OLS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581ba09-d8c3-417f-a156-335152cdb261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a05c1ed-9b08-4b94-826c-43d248967f49",
   "metadata": {},
   "source": [
    "##### 12. Plot the relationship between the predictions from the linear regression in Question 1 (on the x-axis) and the predictions from the logistic regression (on the y-axis). What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d83508-51a2-4d72-bc7f-afc2be2a5853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a2c7d6-54fd-4094-97d5-e45474e9bd14",
   "metadata": {},
   "source": [
    "##### 13. Separating users into communities based on the kind of stories they engage with and other users they interact with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dad3a3-08e9-454b-9b2d-bf55c61b7b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58ee11ba-1bc1-43f6-9774-607198b4dea4",
   "metadata": {},
   "source": [
    "##### 14. Predicting whether users will click on a story or not based on their past behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8fc38-b6c7-4e2d-9a81-14fb90d6086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a516eb79-151c-4c63-ad73-97ea5a529538",
   "metadata": {},
   "source": [
    "##### 15. Choosing which story to show a user in order to keep them active on the platform for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e72ec-f0bb-459b-a395-57f478e2d64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
