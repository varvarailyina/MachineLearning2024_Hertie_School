{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41612d9c-fa12-4e80-9e9e-41b52d094613",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654f23f-e5ea-48b2-b08e-51ac81a46852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5faafaa-5477-4c08-b443-01f83565afdf",
   "metadata": {},
   "source": [
    "The \"ISLP Hitters\" dataset, often referred to simply as the \"Hitters\" dataset, is a dataset commonly used in statistics and machine learning for regression analysis. It is part of the \"Introduction to Statistical Learning with Applications in R\" (ISLR) textbook, hence the abbreviation \"ISLR/ISLP.\"\n",
    "\n",
    "This dataset contains information about Major League Baseball (MLB) hitters and their salaries. It is used to explore the relationship between various factors and a player's salary, making it suitable for regression analysis.\n",
    "\n",
    "Here are the features included in the Hitters dataset:\n",
    "\n",
    "AtBat: Number of times at bat in the previous year.\n",
    "Hits: Number of hits in the previous year.\n",
    "HmRun: Number of home runs in the previous year.\n",
    "Runs: Number of runs in the previous year.\n",
    "RBI: Number of runs batted in in the previous year.\n",
    "Walks: Number of walks in the previous year.\n",
    "Years: Number of years in the major leagues.\n",
    "CAtBat: Number of times at bat during their career.\n",
    "CHits: Number of hits during their career.\n",
    "CHmRun: Number of home runs during their career.\n",
    "CRuns: Number of runs during their career.\n",
    "CRBI: Number of runs batted in during their career.\n",
    "CWalks: Number of walks during their career.\n",
    "League: A factor with levels A and N indicating the player's league at the end of 1986.\n",
    "Division: A factor with levels E and W indicating the player's division at the end of 1986.\n",
    "PutOuts: Number of put outs in the previous year.\n",
    "Assists: Number of assists in the previous year.\n",
    "Errors: Number of errors in the previous year.\n",
    "Salary: Player's salary in thousands of dollars.\n",
    "This dataset is commonly used for regression tasks to predict a player's salary based on the other features provided. It's a valuable resource for teaching and practicing regression techniques in statistics and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b72f9-7c6d-4d80-ab6c-7d1b82313511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ISLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e5871-1177-4ea1-a544-cdd7643418f8",
   "metadata": {},
   "source": [
    "### Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65406bf1-6c04-4ceb-98f1-0d08b63fd303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import load_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502da703-1b24-4697-895d-a7a0cf35ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "Hitters = load_data('Hitters')\n",
    "Hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bab94-75e6-44b1-9b3a-62037889e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting non-numeric variables to numerical by getting dummy variables\n",
    "Hitters['League'] = pd.get_dummies(Hitters['League'], drop_first=True)\n",
    "Hitters['Division'] = pd.get_dummies(Hitters['Division'], drop_first=True)\n",
    "Hitters['NewLeague'] = pd.get_dummies(Hitters['NewLeague'], drop_first=True)\n",
    "Hitters.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608cf265-504a-467a-8cb7-6ee7e0952244",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed695c6-30f4-46cf-9c77-c0b9b2e89e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values by dropping them\n",
    "Hitters.dropna(axis=0, inplace=True)\n",
    "Hitters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba4095-dd4a-4d5a-a0fb-351ce29a966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating features and target variable\n",
    "X = Hitters.drop(['Salary'], axis=1)\n",
    "y = Hitters['Salary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f393f4-3788-4032-bce0-023ff5a8e509",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f3b19d-96f6-4970-8c5c-6dec6cbd034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea54ef-f36c-4dea-b249-5d79a3d36a64",
   "metadata": {},
   "source": [
    "### Set up Cross Validation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62772ac-542b-4fe3-89e1-a24e491aaa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d54aa4-b222-47b1-b592-16092b49b38e",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1c78e-baf1-4612-920f-a2f43060703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## selecting 20 values of alpha\n",
    "alphas = np.logspace(-6, 6, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02588c12-91ce-49dc-8115-b9cdda78d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating mse for different values of alpha:\n",
    "mse_scores_ridge = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        Ridge(alpha=alpha)\n",
    "    )\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    mse_scores_ridge.append(-1 * scores.mean())\n",
    "\n",
    "### scikit-learn's cross-validation functions aim to maximize the scoring function, \n",
    "# so using the negative MSE allows for consistency with this convention.\n",
    "\n",
    "\n",
    "# Identify the best alpha\n",
    "best_alpha_ridge = alphas[np.argmin(mse_scores_ridge)]\n",
    "print(\"Best ridge alpha is\", best_alpha_ridge )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986d91c-cf65-46b3-ab69-789d61b4164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot MSE vs Alpha for Ridge Regression\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.semilogx(alphas, mse_scores_ridge, label='MSE', color='blue', marker='o')\n",
    "##This line creates a plot with logarithmically scaled x-axis (gamma) and linearly scaled y-axis (MSE). \n",
    "# It plots the MSE scores (mse_scores_kernel) against the gamma values (gammas). \n",
    "# The plot is labeled 'MSE', displayed in green color, and marker 'o' is used to represent data points.\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Ridge Regression MSE vs. Alpha')\n",
    "plt.axvline(x=best_alpha_ridge, color='red', linestyle='--', label=f'Best Alpha: {best_alpha_ridge:.2e}')\n",
    "\n",
    "## This line adds a vertical line to the plot at the position of the best gamma (best_gamma_kernel). \n",
    "# The line is colored red, dashed ('--'), and labeled with the value of the best gamma.\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b0395b-32fb-4f93-8287-07f3681f40ff",
   "metadata": {},
   "source": [
    "### Kernel regression for Gaussian Kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3067d31-0d4a-40bf-91a1-7c50006ba45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = np.logspace(-4, -1, 20)\n",
    "alpha_optimal_kernel_ridge = best_alpha_ridge  # Use the best alpha found for Ridge or another value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de37a3-c035-4243-9b1f-5d2a40a9c22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating mse for different Gammas:\n",
    "mse_scores_kernel = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KernelRidge(alpha=alpha_optimal_kernel_ridge, kernel='rbf', gamma=gamma)\n",
    "    )\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring='neg_mean_squared_error', cv=kf)\n",
    "    mse_scores_kernel.append(-1 * scores.mean())\n",
    "\n",
    "# Identify the best gamma\n",
    "best_gamma_kernel = gammas[np.argmin(mse_scores_kernel)]\n",
    "print(\"best gamma is\", best_gamma_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9677bd-45db-4dd9-a7c9-2504a343d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MSE vs Gamma for Kernel Ridge Regression using Gaussian Kernels:\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.semilogx(gammas, mse_scores_kernel, label='MSE', color='green', marker='o')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Kernel Ridge Regression MSE vs. Gamma')\n",
    "plt.axvline(x=best_gamma_kernel, color='red', linestyle='--', label=f'Best Gamma: {best_gamma_kernel:.2e}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d63fa9a-14cc-4984-b102-96ea1908594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test MSe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49542c-23f4-4438-936d-67ab07b8ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge model with best alpha\n",
    "ridge_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    Ridge(alpha=best_alpha_ridge)\n",
    ")\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "\n",
    "# Kernel Ridge model with best gamma\n",
    "kernel_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KernelRidge(alpha=alpha_optimal_kernel_ridge, kernel='rbf', gamma=best_gamma_kernel)\n",
    ")\n",
    "kernel_model.fit(X_train, y_train)\n",
    "y_pred_kernel = kernel_model.predict(X_test)\n",
    "mse_kernel = mean_squared_error(y_test, y_pred_kernel)\n",
    "\n",
    "print(f\"Test MSE for Ridge: {mse_ridge}\")\n",
    "print(f\"Test MSE for Kernel Ridge: {mse_kernel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15ee5e7-2237-48d1-b8b0-521ec6f6b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mse_ridge < mse_kernel:\n",
    "    print(\"Ridge Regression performs better on the test set.\")\n",
    "else:\n",
    "    print(\"Kernel Ridge Regression performs better on the test set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc2ade7-4a1d-4054-b556-0c58d0e1b81d",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30d223-602c-4255-a740-8ed601df0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define degrees for polynomial features\n",
    "degrees = [2, 3, 4,5,6]\n",
    "\n",
    "# Evaluate Polynomial Regression across degrees\n",
    "mse_scores_poly = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = make_pipeline(\n",
    "        \n",
    "    )\n",
    "    scores = \n",
    "    mse_scores_poly.append(-1 * scores.mean())\n",
    "\n",
    "# Identify the best degree for Polynomial Regression\n",
    "best_degree_poly = degrees[np.argmin(mse_scores_poly)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9d577-ac23-4c6c-b5d4-f13047b63f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE vs. degree for Polynomial Regression\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(degrees, mse_scores_poly, label='MSE', color='green', marker='o')\n",
    "plt.xlabel('Degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Polynomial Regression MSE vs. Degree')\n",
    "plt.axvline(x=best_degree_poly, color='red', linestyle='--', label=f'Best Degree: {best_degree_poly}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112aa00f-3355-463d-a17d-1dfc3aa72717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Polynomial Regression model with best degree\n",
    "poly_model = make_pipeline(\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"Test MSE for Ridge Regression:\", mse_ridge)\n",
    "print(\"Test MSE for Polynomial Regression:\", mse_poly)\n",
    "\n",
    "# Determine which model performs better\n",
    "if mse_ridge < mse_poly:\n",
    "    print(\"Ridge Regression performs better on the test set.\")\n",
    "else:\n",
    "    print(\"Polynomial Regression performs better on the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f11a17-55f1-460c-865d-8387ddb28d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
