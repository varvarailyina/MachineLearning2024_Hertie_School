{"cells":[{"cell_type":"code","execution_count":null,"id":"ed7c5e2a-40c2-4e75-9ccf-04e246085871","metadata":{"id":"ed7c5e2a-40c2-4e75-9ccf-04e246085871"},"outputs":[],"source":["# Import the Libraries\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.metrics import accuracy_score\n"]},{"cell_type":"code","source":[],"metadata":{"id":"nnp3UJypEjKJ"},"id":"nnp3UJypEjKJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using Dropout https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success Data."],"metadata":{"id":"koj0_W4gEnig"},"id":"koj0_W4gEnig"},{"cell_type":"code","execution_count":null,"id":"9ee24b27-e891-431b-b3b4-4e37d5745332","metadata":{"id":"9ee24b27-e891-431b-b3b4-4e37d5745332"},"outputs":[],"source":["# Load the datasets\n","df = pd.read_csv(\"dropoutData.csv\")\n","df.shape\n"]},{"cell_type":"code","execution_count":null,"id":"039c35a9-b211-4120-80c7-12e99c5d224d","metadata":{"id":"039c35a9-b211-4120-80c7-12e99c5d224d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3ce31d1c-021b-41af-854d-0561d9ea01d3","metadata":{"id":"3ce31d1c-021b-41af-854d-0561d9ea01d3"},"outputs":[],"source":["train_ratio = 0.7\n","\n","\n","# split whole into train and test, then split test into val and test\n","X_train, X_test, y_train, y_test = train_test_split(df.drop('Target', axis=1), df['Target'], train_size=train_ratio, random_state=123)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ecf537ff-9a04-40ac-90a6-55e9501a7d1d","metadata":{"id":"ecf537ff-9a04-40ac-90a6-55e9501a7d1d"},"outputs":[],"source":["val_ratio = 0.15\n","test_ratio = 0.15\n","\n","X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=val_ratio/(val_ratio + test_ratio), random_state=123)\n","n_train = X_train.shape[0]\n","n_val = X_val.shape[0]\n","n_test = X_test.shape[0]\n","n = n_train + n_val + n_test\n","print(f'No. of train samples: {X_train.shape} \\n')\n","print(f'No. of val samples: {X_val.shape} \\n')\n","print(f'No. of test samples: {X_test.shape} \\n')\n","print(f'No. of train samples: {y_train.shape} \\n')\n","print(f'No. of val samples: {y_val.shape} \\n')\n","print(f'No. of test samples: {y_test.shape} \\n')\n","print(f'Train test val ratio: {n_train/n}, {n_test/n}, {n_val/n}')"]},{"cell_type":"code","execution_count":null,"id":"67f1e668-b0b4-45a5-80c3-33f0eeb1c521","metadata":{"id":"67f1e668-b0b4-45a5-80c3-33f0eeb1c521"},"outputs":[],"source":["# converting dataframe to numpy array because pytorch takes numpy arrays (or torch.tensor) as input.\n","X_train=X_train.to_numpy()\n","X_test=X_test.to_numpy()\n","X_val=X_val.to_numpy()\n","y_train=y_train.to_numpy()\n","y_test=y_test.to_numpy()\n","y_val=y_val.to_numpy()\n","type(X_train)\n","print(f'No. of train samples: {X_train.shape} \\n')\n","print(f'No. of val samples: {X_val.shape} \\n')\n","print(f'No. of test samples: {X_test.shape} \\n')\n","print(f'No. of train samples: {y_train.shape} \\n')\n","print(f'No. of val samples: {y_val.shape} \\n')\n","print(f'No. of test samples: {y_test.shape} \\n')"]},{"cell_type":"code","execution_count":null,"id":"64246173-4724-4f50-9321-2f0c0a41042a","metadata":{"id":"64246173-4724-4f50-9321-2f0c0a41042a"},"outputs":[],"source":["from torch.utils.data import DataLoader, TensorDataset\n","import torch"]},{"cell_type":"code","execution_count":null,"id":"6cce1a11-3414-43c5-8cb9-e93ba4bec666","metadata":{"id":"6cce1a11-3414-43c5-8cb9-e93ba4bec666"},"outputs":[],"source":["train_dataset = TensorDataset(torch.tensor(X_train).float(), torch.tensor(y_train).long())\n","val_dataset= TensorDataset(torch.tensor(X_val).float(), torch.tensor(y_val).long())\n","test_dataset=TensorDataset(torch.tensor(X_test).float(), torch.tensor(y_test).long())\n"]},{"cell_type":"code","execution_count":null,"id":"f196a461-8437-4f77-9b37-17b1d5cede36","metadata":{"id":"f196a461-8437-4f77-9b37-17b1d5cede36"},"outputs":[],"source":["## Dataloader\n","\n","train_bs = 32\n","val_bs = 32\n","test_bs = 32\n","\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=train_bs, shuffle=True, drop_last=True) #dataset\n","val_dataloader = DataLoader(val_dataset, batch_size=val_bs, shuffle=False, drop_last=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=test_bs, shuffle=False, drop_last=True)\n","\n","# train_dataloader\n","\n","print(f'No. of batches train dataloader: {len(train_dataloader)} and total train samples: {len(train_dataloader)*train_bs}, {train_dataloader.batch_size}')\n","print(f'No. of batches val dataloader: {len(val_dataloader)} and total val samples: {len(val_dataloader)*val_bs}')\n","print(f'No. of batches test dataloader: {len(test_dataloader)} and test train samples: {len(test_dataloader)*test_bs}')\n","# X = next(iter(train_dataloader))\n","\n","# (X,y) = next(iter(train_dataloader))"]},{"cell_type":"code","execution_count":null,"id":"4520e217-8192-4524-a215-2391c6b059a1","metadata":{"id":"4520e217-8192-4524-a215-2391c6b059a1"},"outputs":[],"source":["# print(X[1])"]},{"cell_type":"code","execution_count":null,"id":"639836f3-401b-4a60-8c68-9c2d2bef4d75","metadata":{"id":"639836f3-401b-4a60-8c68-9c2d2bef4d75"},"outputs":[],"source":["# Train and evaluate functions for training and validating the model\n","\n","def train_loop(model, tr_dataloader, loss_fn, opt):\n","    avg_loss = 0 # to store running loss\n","    model.train() # Set model in training mode\n","    for batch_idx, (X, y) in enumerate(tr_dataloader):\n","        pred = model(X) # make prediction on current batch\n","        loss = loss_fn(pred,y) # calculate loss\n","        loss.backward() # calculates gradients\n","        opt.step() # update weights\n","        opt.zero_grad() # set gradients to zero for next batch\n","        avg_loss += loss.item()\n","        #print(f'Batch no. {batch_idx}, Batch loss: {loss.item():.5f}')\n","    print(f'Average training Loss: {avg_loss/len(tr_dataloader):.5f}')\n","    train_loss = avg_loss/len(tr_dataloader)\n","    return train_loss\n","\n","def test_loop(model, dataloader, loss_fn ):\n","    test_loss = 0.\n","    correct = 0\n","    model.eval()\n","    bs = dataloader.batch_size\n","    for batch_idx, (X, y) in enumerate(dataloader):\n","        pred = model(X) # make prediction on current batch\n","        test_loss += loss_fn(pred,y).item() # calculate loss\n","        correct += (pred.argmax(1) == y).type(torch.float).sum().item() # not required for regression\n","\n","    test_loss /= len(dataloader)\n","    correct /= (len(dataloader)*dataloader.batch_size)\n","    print(f'Error: \\n Accuracy: {(100*correct):0.1f}%, Avg test loss: {test_loss:.5f} \\n')\n","\n","\n","    return test_loss\n",""]},{"cell_type":"code","execution_count":null,"id":"98d9cc16-04f2-4228-b99f-e602b7d964b4","metadata":{"scrolled":true,"id":"98d9cc16-04f2-4228-b99f-e602b7d964b4"},"outputs":[],"source":["# define a model class # Model 1\n","from torch import nn, optim\n","\n","class Network(nn.Module):\n","    def __init__(self,hid_layer=[100,100]):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(34, hid_layer[0]),\n","            nn.ReLU(),\n","            nn.Linear(hid_layer[0],hid_layer[1]),\n","            nn.ReLU(),\n","            nn.Linear(hid_layer[1], 2),\n","        )\n","    def forward(self,x):\n","        logits = self.net(x)\n","        return logits\n","\n"]},{"cell_type":"code","execution_count":null,"id":"9a82e7f7-918d-4aa9-bc62-6b0d30e25079","metadata":{"id":"9a82e7f7-918d-4aa9-bc62-6b0d30e25079"},"outputs":[],"source":["## Calling model 1\n","hid_layer = [80,45] # number of nodes\n","model = Network(hid_layer) #instantiate\n","\n","epochs = 20\n","learning_rate = 1e-2\n","loss_fn = nn.CrossEntropyLoss()\n","opt = optim.Adam(model.parameters(), lr=learning_rate)\n","train_loss = [] # list to store train loss\n","val_loss = [] # list to store val loss\n","\n","for t in range(epochs):\n","    print(f'Epoch {t}')\n","    train_loss.append(train_loop(model, train_dataloader,  loss_fn, opt)) # to plot the graph\n","    val_loss.append(test_loop(model, val_dataloader, loss_fn))\n","\n"]},{"cell_type":"code","execution_count":null,"id":"f37ee2e2-654a-4425-87cc-f8d11cc9c8e2","metadata":{"id":"f37ee2e2-654a-4425-87cc-f8d11cc9c8e2"},"outputs":[],"source":["\n","from matplotlib import pyplot as plt\n","xax = range(epochs)\n","plt.plot(xax, np.array(train_loss),'r-', xax, np.array(val_loss),'g-'  )\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend(['Train loss','Val loss' ])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"55c2945c-d4e2-4879-a0ab-e836cad2e791","metadata":{"id":"55c2945c-d4e2-4879-a0ab-e836cad2e791"},"outputs":[],"source":["print('Performing test...\\n')\n","test_loop(model,test_dataloader,loss_fn)"]},{"cell_type":"code","execution_count":null,"id":"e8b92502-5792-4fcc-a327-eef1ce24d28d","metadata":{"id":"e8b92502-5792-4fcc-a327-eef1ce24d28d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}