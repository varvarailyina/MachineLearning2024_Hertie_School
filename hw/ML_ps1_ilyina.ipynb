{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d7c91c1-db98-4ee1-b5ac-dc677b0571ee",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "***\n",
    "#### Problem Set 1\n",
    "#### Varvara Ilyina\n",
    "#### 2024-02-28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a54101-3c27-4ad0-9d5a-5cdceeb83381",
   "metadata": {},
   "source": [
    "The following exercises have been solved with the help of the lecture slides, as well as Chapters 1, 4 and 5 in _Probabilistic Machine Learning: An Introduction_ by Kevin Murphy. Additionally, various internet resources, friends and ChatGPT were used to aid me in generating the correct commands for my Python code (especially for questions 5, 7 and 8).\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fbeeb2-95f2-4777-a1c1-d62380cae7aa",
   "metadata": {},
   "source": [
    "#### 1. The particular task we will be considering is predicting `vote` based on five features: `TVnews`, `PID`, `age`, `educ`, and `popul`. Calculate summary statistics for the label and five features described above. Pay attention to the meaning of each variable and present a summary of it that makes sense given how it is coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b5637a7d-8d56-4048-bbcc-701f33a82675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "71284c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(944, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TVnews</th>\n",
       "      <th>PID</th>\n",
       "      <th>age</th>\n",
       "      <th>educ</th>\n",
       "      <th>popul</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TVnews  PID   age  educ  popul  vote\n",
       "0     7.0  6.0  36.0   3.0    0.0   1.0\n",
       "1     1.0  1.0  20.0   4.0  190.0   0.0\n",
       "2     7.0  1.0  24.0   6.0   31.0   0.0\n",
       "3     4.0  1.0  28.0   6.0   83.0   0.0\n",
       "4     7.0  0.0  68.0   6.0  640.0   0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = sm.datasets.anes96.load_pandas().data\n",
    "\n",
    "# extract necessary columns\n",
    "features = ['TVnews', 'PID', 'age', 'educ', 'popul']\n",
    "label = 'vote'\n",
    "df = data[features + [label]]\n",
    "\n",
    "# replace missings with NaN\n",
    "df = df.replace('?', np.nan)\n",
    "\n",
    "# drop missing values\n",
    "df = df.dropna(axis = 1)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2875d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           TVnews         PID         age        educ        popul        vote\n",
      "count  944.000000  944.000000  944.000000  944.000000   944.000000  944.000000\n",
      "mean     3.727754    2.842161   47.043432    4.565678   306.381356    0.416314\n",
      "std      2.677235    2.273337   16.423130    1.599287  1082.606745    0.493208\n",
      "min      0.000000    0.000000   19.000000    1.000000     0.000000    0.000000\n",
      "25%      1.000000    1.000000   34.000000    3.000000     1.000000    0.000000\n",
      "50%      3.000000    2.000000   44.000000    4.000000    22.000000    0.000000\n",
      "75%      7.000000    5.000000   58.000000    6.000000   110.000000    1.000000\n",
      "max      7.000000    6.000000   91.000000    7.000000  7300.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "# print summary statistics\n",
    "summary = df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c40ed29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22289631  1.38981276 -0.67278806 -0.97950413 -0.28315338]\n",
      " [-1.01941016 -0.81076296 -1.64754019 -0.35389391 -0.10755803]\n",
      " [ 1.22289631 -0.81076296 -1.40385216  0.89732651 -0.25450362]\n",
      " ...\n",
      " [-0.27197467  0.94969762 -0.24633401  0.89732651 -0.28315338]\n",
      " [ 0.84917856  1.38981276 -0.06356798  1.52293673 -0.28315338]\n",
      " [ 1.22289631  0.06946733  0.85026213  1.52293673 -0.26651803]]\n"
     ]
    }
   ],
   "source": [
    "# index df using `iloc`\n",
    "X_no_intercept = df.iloc[:, 0:5].values  # data from first 5 columns\n",
    "y = df.iloc[:, 5].values  # extract attribute/feature to be predicted from 6th column of df\n",
    "\n",
    "# use seed to get a randomized sample with a 70%/30% split\n",
    "seed = 0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = seed)\n",
    "\n",
    "# standardize testing data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(X_no_intercept)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fe77c434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X features:\n",
      "      intercept    TVnews       PID       age      educ     popul\n",
      "0          1.0  1.222896  1.389813 -0.672788 -0.979504 -0.283153\n",
      "1          1.0 -1.019410 -0.810763 -1.647540 -0.353894 -0.107558\n",
      "2          1.0  1.222896 -0.810763 -1.403852  0.897327 -0.254504\n",
      "3          1.0  0.101743 -0.810763 -1.160164  0.897327 -0.206446\n",
      "4          1.0  1.222896 -1.250878  1.276716  0.897327  0.308326\n",
      "..         ...       ...       ...       ...       ...       ...\n",
      "939        1.0  1.222896  0.509582  1.581326  0.897327 -0.283153\n",
      "940        1.0  1.222896  1.389813  0.180120  0.897327 -0.283153\n",
      "941        1.0 -0.271975  0.949698 -0.246334  0.897327 -0.283153\n",
      "942        1.0  0.849179  1.389813 -0.063568  1.522937 -0.283153\n",
      "943        1.0  1.222896  0.069467  0.850262  1.522937 -0.266518\n",
      "\n",
      "[944 rows x 6 columns]\n",
      "Y label:\n",
      " 0      1.0\n",
      "1      0.0\n",
      "2      0.0\n",
      "3      0.0\n",
      "4      0.0\n",
      "      ... \n",
      "939    1.0\n",
      "940    1.0\n",
      "941    1.0\n",
      "942    1.0\n",
      "943    1.0\n",
      "Name: vote, Length: 944, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# add intercept\n",
    "X_train_intercept = sm.add_constant(X_train)\n",
    "\n",
    "# create dataframe\n",
    "X_train_intercept = pd.DataFrame(X_train_intercept, columns = ['intercept', 'TVnews', 'PID', 'age', 'educ', 'popul'])\n",
    "print(\"X features:\\n\", X_train_intercept)\n",
    "\n",
    "y_train = df.iloc[:, 5]\n",
    "print(\"Y label:\\n\", y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccbec7c-925e-4933-b59e-8b3de3a41a82",
   "metadata": {},
   "source": [
    "#### 2. What is the formula for the closed form estimate of the coefficient vector in ordinary least squares regression? Estimate the coefficients using `numpy` in Python by performing the matrix operations from the closed form solution we worked out in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679467c0",
   "metadata": {},
   "source": [
    "__Solution__: The closed form solution is $\\hat{\\beta} = (X^TX)^{-1}X^Ty$. This formula is used to estimate the coefficients in OLS regression below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e97bea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated coefficients (closed form solution):\n",
      " 0    0.416314\n",
      "1    0.004639\n",
      "2    0.392557\n",
      "3    0.022259\n",
      "4    0.005333\n",
      "5    0.000051\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# estimate coefficients using the closed-form solution\n",
    "beta = np.linalg.inv(X_train_intercept.T @ X_train_intercept) @ X_train_intercept.T @ y_train\n",
    "\n",
    "print(\"Estimated coefficients (closed form solution):\\n\", beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7fdc5-b66f-4b32-9b16-b45f887f02d0",
   "metadata": {},
   "source": [
    "#### 3. Estimate the coefficients using the `statsmodels` package. Compare them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4275f0d0",
   "metadata": {},
   "source": [
    "__Solution__: Both estimations, whether with an ordinary least squares regression or the `statsmodel` package, result in the same coefficients. The work to prove this is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7376311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated coefficients (statsmodel OLS):\n",
      "                             OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   vote   R-squared:                       0.638\n",
      "Model:                            OLS   Adj. R-squared:                  0.636\n",
      "Method:                 Least Squares   F-statistic:                     330.9\n",
      "Date:                Wed, 28 Feb 2024   Prob (F-statistic):          3.46e-204\n",
      "Time:                        18:44:29   Log-Likelihood:                -191.93\n",
      "No. Observations:                 944   AIC:                             395.9\n",
      "Df Residuals:                     938   BIC:                             425.0\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      0.4163      0.010     42.999      0.000       0.397       0.435\n",
      "TVnews         0.0046      0.011      0.436      0.663      -0.016       0.026\n",
      "PID            0.3926      0.010     40.087      0.000       0.373       0.412\n",
      "age            0.0223      0.011      2.070      0.039       0.001       0.043\n",
      "educ           0.0053      0.010      0.541      0.589      -0.014       0.025\n",
      "popul       5.051e-05      0.010      0.005      0.996      -0.019       0.019\n",
      "==============================================================================\n",
      "Omnibus:                       70.909   Durbin-Watson:                   1.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              210.328\n",
      "Skew:                          -0.350   Prob(JB):                     2.13e-46\n",
      "Kurtosis:                       5.204   Cond. No.                         1.61\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model = sm.OLS(y_train, X_train_intercept).fit()\n",
    "\n",
    "print(\"Estimated coefficients (statsmodel OLS):\\n\", model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7ce7ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients from closed form solution:\n",
      " 0    0.416314\n",
      "1    0.004639\n",
      "2    0.392557\n",
      "3    0.022259\n",
      "4    0.005333\n",
      "5    0.000051\n",
      "dtype: float64\n",
      "Coefficients from statsmodels:\n",
      " intercept    0.416314\n",
      "TVnews       0.004639\n",
      "PID          0.392557\n",
      "age          0.022259\n",
      "educ         0.005333\n",
      "popul        0.000051\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# compare coefficients\n",
    "print(\"Coefficients from closed form solution:\\n\", beta)\n",
    "print(\"Coefficients from statsmodels:\\n\", model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441b84d-c640-474b-a326-a38fe090ff6c",
   "metadata": {},
   "source": [
    "#### 4. Now, think about the model you just estimated. In class, we talked about two assumptions we could use to motivate estimation of the variance of this coefficient vector. Which would you choose and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91168d3e",
   "metadata": {},
   "source": [
    "__Solution__: In the plot below, two parallel lines are seen. Since the results are not binary, they are difficult to interpret. With the help of ChatGPT, I was able to determine that the variance $\\sigma^{2}$ varies between units, thus indicating _heteroskedasticity_. This violates the basic assumption of linear regression models and can lead to biased estimates of the regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb56c0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "residuals = sm_results.resid\n",
    "\n",
    "plt.scatter(sm_results.fittedvalues, residuals)\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.xlabel(\"fitted values\")\n",
    "plt.ylabel(\"residuals\")\n",
    "plt.axhline(y = 0, color = 'black', linestyle = '-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db81a40-9626-4f3c-abfe-03747dfa8c1c",
   "metadata": {},
   "source": [
    "#### 5. Estimate the variance of these coefficients using the matrix formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403ee9e0",
   "metadata": {},
   "source": [
    "__Solution__: To estimate the variance of the coefficients, I apply the concept of the \"sandwich\" estimator using the matrix formula $\\text{Var}(\\hat{\\beta}) = (X^T X)^{-1} X^T \\text{diag}(\\hat{e}^2) X (X^T X)^{-1}$. This formula is used to correct any bias resulting from the heteroskedasticity found above. $\\hat{e}^2 = (y - \\hat{y})^2$ is used to calculate the squared residuals, where $\\hat{e}^2$ are the squared differences between the observed values ($y$) and the predicted values ($\\hat{y}$) obtained from the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6ffdbf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 944)\n",
      "(944, 944)\n",
      "(944, 6)\n",
      "Estimated variance of coefficients:\n",
      "           0             1         2         3             4         5\n",
      "0  0.000093  3.645171e-06  0.000028  0.000002 -2.560040e-06  0.000012\n",
      "1  0.000004  1.151078e-04  0.000013 -0.000042  8.624614e-08  0.000013\n",
      "2  0.000028  1.318217e-05  0.000066 -0.000009 -1.625723e-05  0.000008\n",
      "3  0.000002 -4.166116e-05 -0.000009  0.000107  2.010585e-05 -0.000001\n",
      "4 -0.000003  8.624614e-08 -0.000016  0.000020  9.479563e-05  0.000015\n",
      "5  0.000012  1.255711e-05  0.000008 -0.000001  1.529698e-05  0.000155\n"
     ]
    }
   ],
   "source": [
    "# calculate needed values\n",
    "X = X_train_intercept\n",
    "y = y_train\n",
    "\n",
    "# generate diagonal matrix of residuals\n",
    "resid_diag_matrix = np.diag(residuals ** 2)\n",
    "\n",
    "# calculate \"sandwich\" values\n",
    "bread_1 = np.linalg.inv(X.T @ X) @ X.T\n",
    "meat = resid_diag_matrix\n",
    "bread_2 = X @ np.linalg.inv(X.T @ X)\n",
    "\n",
    "# check matrix dimensions\n",
    "print(bread_1.shape)\n",
    "print(meat.shape)\n",
    "print(bread_2.shape)\n",
    "\n",
    "# plug into \"sandwich\" formula\n",
    "variance_coeff = bread_1 @ meat @ bread_2\n",
    "print(\"Estimated variance of coefficients:\\n\", variance_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68887f16-e4c1-477b-8c75-9e757d4a6d72",
   "metadata": {},
   "source": [
    "#### 6. Create a table showing, for each feature, _j_, the estimate ($\\hat{β}_{j}$), the standard error $\\sqrt{\\hat{Var}(\\hat{β})}_{jj}$, and the upper and lower bounds of the 95% confidence interval ($\\hat{β}_{j}±z_{\\alpha}\\sqrt{\\hat{Var}(\\hat{β})}_{jj}$). Compare the variance to what you got from statsmodels. What assumption are they using on the variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "747558ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  Coefficient  Std. Error  Lower Bound (95% CI)  \\\n",
      "0  Intercept     0.416314    0.009651              0.397398   \n",
      "1     TVnews     0.004639    0.010729             -0.016389   \n",
      "2        PID     0.392557    0.008107              0.376667   \n",
      "3        age     0.022259    0.010340              0.001993   \n",
      "4       educ     0.005333    0.009736             -0.013749   \n",
      "5      popul     0.000051    0.012445             -0.024342   \n",
      "\n",
      "   Upper Bound (95% CI)  \n",
      "0              0.435229  \n",
      "1              0.025667  \n",
      "2              0.408447  \n",
      "3              0.042525  \n",
      "4              0.024416  \n",
      "5              0.024443  \n"
     ]
    }
   ],
   "source": [
    "# specify features\n",
    "features_int = ['Intercept'] + features\n",
    "\n",
    "# calculate standard error\n",
    "std_err = np.sqrt(np.diag(variance_coeff))\n",
    "\n",
    "# calculate upper / lower bounds of 95% confidence interval\n",
    "z_alpha = norm.ppf(0.975)\n",
    "\n",
    "lower_bound = beta - z_alpha * std_err\n",
    "upper_bound = beta + z_alpha * std_err\n",
    "\n",
    "# generate table\n",
    "table_6 = pd.DataFrame({'Feature': features_int,\n",
    "                        'Coefficient': beta,\n",
    "                        'Std. Error': std_err,\n",
    "                        'Lower Bound (95% CI)': lower_bound,\n",
    "                        'Upper Bound (95% CI)': upper_bound})\n",
    "\n",
    "print(table_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e69a1d8-1e5c-4466-840c-f059b43b9cfd",
   "metadata": {},
   "source": [
    "#### 7. Write a function with three arguments:\n",
    "* `beta`: A 1D numpy array representing a particular value of your coefficients, $β$.\n",
    "* `label`: A 1D numpy array of the labels in your dataset.\n",
    "* `features`: A 2D numpy array representing the features in your dataset.\n",
    "##### This function should output a single number, the negative log-likelihood evaluated at the chosen value of $β$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fd4ecb",
   "metadata": {},
   "source": [
    "I had help from ChatGPT for this exercise, as I am still new to writing Python code.\n",
    "\n",
    "Input into my `nll` function are three arguments, namely the `beta` coefficient, the `label` with `vote` and then the five `features` . Within the function, I first create `features_coeff` for the scores for each observations, which represent the strength of the association between the feature and the outcome. Next, I apply the sigmoid function to transform these into interpretable probabilities ($\\hat{p}$). The negative log likelihood is a quantitative measure of how well the model was able to predict the data, i.e., whether the predicted probabilities align with the actual observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ad974aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "def nll(beta, label, features):\n",
    "    features_coeff = np.dot(features, beta)\n",
    "    p_hat = 1 / (1 + np.exp(-features_coeff))\n",
    "    nll_value = -np.sum(label * np.log(p_hat) + (1 - label) * np.log(1 - p_hat))\n",
    "    return nll_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e10294-059b-4e5b-b4bf-1de32e88a144",
   "metadata": {},
   "source": [
    "#### 8. Using the `SciPy` library, minimize the objective function we discussed in class for logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c20450",
   "metadata": {},
   "source": [
    "The `nll` function is adjusted to restrict the outputted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9795ec67-cb79-4b9f-a6f2-7e75718717df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# me\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "opt_result = scipy.optimize.minimize(\n",
    "nll, args = (X, y), x0 = [0] * 6, method = 'BFGS'\n",
    ")\n",
    "beta_logistic = opt_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991226c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# armande\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def negative_log_likelihood(beta, X, y):\n",
    "    features_coeff = np.dot(X, beta)\n",
    "    p_hat = 1 / (1 + np.exp(-features_coeff))\n",
    "    eps = np.finfo(float).eps #use of the command to know the smallest floating point number\n",
    "    p_hat_clipped = np.clip(p_hat, eps, 1 - eps)  # Clip probabilities to avoid zeros and ones\n",
    "    nll = -np.sum(y * np.log(p_hat_clipped) + (1 - y) * np.log(1 - p_hat_clipped))\n",
    "    return nll\n",
    "\n",
    "initial_beta = np.zeros(X.shape[1])\n",
    "\n",
    "# Minimize the negative log-likelihood function\n",
    "opt_result = minimize(negative_log_likelihood, initial_beta, args=(X, y), method='BFGS')\n",
    "\n",
    "# Extract the optimal coefficients\n",
    "beta_logistic = opt_result.x\n",
    "\n",
    "print(\"Optimal coefficients:\", beta_logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e555e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# giulia\n",
    "\n",
    "def nll_function(beta, features, label):  # same function as above but we are clipping, or bounding, values within  specified range \n",
    "    # we need the features coefficients to reproduce scores for each observation\n",
    "    # the scores represent the strenght of association between the feature and the outcome \n",
    "    features_coeff = np.dot(features, beta) \n",
    "    # to trasform the raw scores into interpretable probabilities of class membership (Dole or Clinton), we apply the sigmoid function \n",
    "    p_hat = 1 / (1 + np.exp(-features_coeff))\n",
    "\n",
    "    eps = np.finfo(float).eps # a very small number close to zero\n",
    "    # np.clip() function is used to ensure that the predicted probabilities (p_hat) are bounded between eps and 1 - eps\n",
    "    # its basically to avoid 0 but still getting extremely close to it \n",
    "    p_hat_clipped = np.clip(p_hat, eps, 1 - eps) # p_hat variable used here is the clipped version\n",
    "    # This ensures that the predicted probabilities passed to the negative log-likelihood calculation are within a valid range \n",
    "    \n",
    "    # next step quantifies how well the model's predicted probabilities align with the actual labels observed in the dataset.\n",
    "    nll = -np.sum(label * np.log(p_hat_clipped) + (1 - label) * np.log(1 - p_hat_clipped))\n",
    "    return nll # discrepancy between the observed data and the predictions made by the model\n",
    "\n",
    "initial_beta = np.zeros(X.shape[1])  # ChatGPT suggested this and taught me its scope in this function \n",
    "# By setting the initial coefficients to zero, the optimization algorithm starts from a neutral point \n",
    "# The algorithm iteratively adjusts the coefficients to minimize the negative log-likelihood function\n",
    "\n",
    "# Minimize the negative log-likelihood function\n",
    "opt_result = minimize(nll_function, initial_beta, args=(X, y), method='BFGS')\n",
    "\n",
    "beta_logistic = opt_result.x# these are the optimal coefficients \n",
    "\n",
    "print(\"Optimal coefficients:\", beta_logistic)\n",
    "\n",
    "# These coefficients are optimal because they do a better job at minimizing the difference the observed data and the predictions made by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d86cfa-c124-4e13-87d9-9e887fa6a5b3",
   "metadata": {},
   "source": [
    "#### 9. Now you can construct your predictions by taking the dot-product between beta logistic and your feature matrix and then passing that dot-product through the sigmoid function. This provides an estimate of the probability of class membership. Also calculate the most likely class for each unit by predicting a 1 when $p(y$<sub>i</sub>$|x$<sub>i</sub>$; β) > 0.5$ (i.e. the Heaviside function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d30d03-d3ed-48c2-a5b3-65b9a4220a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7277f3d1-e873-42c4-b31c-8b65dcabd490",
   "metadata": {},
   "source": [
    "#### 10. Construct class estimates for your OLS predictions as well by calculating $1(Xβ_{ols} > 0.5)$ (i.e. output a $1$ if the OLS predicted value is greater than $0.5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb68d86-93e3-40b8-8db2-9ea4645ce725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486121d4-9987-439a-a6f0-0b805839e0a2",
   "metadata": {},
   "source": [
    "#### 11. Calculate the full confusion matrix for the logistic regression and the OLS model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581ba09-d8c3-417f-a156-335152cdb261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a05c1ed-9b08-4b94-826c-43d248967f49",
   "metadata": {},
   "source": [
    "#### 12. Plot the relationship between the predictions from the linear regression in Question 1 (on the x-axis) and the predictions from the logistic regression (on the y-axis). What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d83508-51a2-4d72-bc7f-afc2be2a5853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8a2c7d6-54fd-4094-97d5-e45474e9bd14",
   "metadata": {},
   "source": [
    "#### 13. Separating users into communities based on the kind of stories they engage with and other users they interact with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dad3a3-08e9-454b-9b2d-bf55c61b7b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58ee11ba-1bc1-43f6-9774-607198b4dea4",
   "metadata": {},
   "source": [
    "#### 14. Predicting whether users will click on a story or not based on their past behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8fc38-b6c7-4e2d-9a81-14fb90d6086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a516eb79-151c-4c63-ad73-97ea5a529538",
   "metadata": {},
   "source": [
    "#### 15. Choosing which story to show a user in order to keep them active on the platform for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e72ec-f0bb-459b-a395-57f478e2d64c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
