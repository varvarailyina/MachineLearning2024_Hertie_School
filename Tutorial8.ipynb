{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5425a99f-e2b9-4201-8d1f-174630e567c4",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed170bac-e0ac-4519-88cc-5c2c4e75d3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef186eb-3031-4d93-ae2e-b0d39f609e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58e683-ba51-4196-ac39-bf1a1c189f15",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd38b8-15d5-4006-9d8b-428b1eeb55d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "carseats = pd.read_csv('Carseats.csv')\n",
    "# Convert 'Sales' into a binary classification target variable 'High'\n",
    "carseats['High'] = carseats['Sales'] > 8\n",
    "# One-hot encode categorical variables\n",
    "carseats = pd.get_dummies(carseats, columns=['ShelveLoc', 'Urban', 'US'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08443c4-33cc-4f48-b7cc-d9ac37a0e803",
   "metadata": {},
   "outputs": [],
   "source": [
    "carseats.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39de7c3-346c-418b-9c71-cbfe18287407",
   "metadata": {},
   "source": [
    "### Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab6fbc-6288-4e6b-9ed5-289a74cd6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and labels\n",
    "X = carseats.drop(['High', 'Sales'], axis=1)\n",
    "y = carseats['High'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1acbd25-dc6a-470a-a67e-bdcf588e91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376c8915-f6af-49cc-a919-c5e32403b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91654928-980b-4521-bac8-d46f962f3366",
   "metadata": {},
   "source": [
    "### Initial XGBoost Model Training\n",
    "\n",
    "For regression, reg:squarederror\n",
    "For multiclass classification (predict one outcome from more than two possible classes) XGBoost uses the multi:softprob and multi:softmax objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472e12a-f43b-4c92-8bcb-574ad2731f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393bcb6-6373-445d-ac6e-cb6e1bd2b9a2",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV\n",
    "The param_grid is designed for tuning an XGBoost model, specifying a range of values for six key hyperparameters that control its behavior and performance:\n",
    "\n",
    "**max_depth**: Maximum tree depth for base learners; deeper trees can model more complex patterns but may lead to overfitting.\n",
    "\n",
    "**min_child_weight**: Minimum sum of instance weight needed in a child; higher values prevent learning very specific patterns, thereby controlling overfitting.\n",
    "\n",
    "**learning_rate (also known as eta)**: Step size shrinkage used to enhance model robustness by preventing overfitting; smaller values require more boosting rounds but can lead to better generalization.\n",
    "\n",
    "**n_estimators**: Number of trees to build; more trees can capture more complex patterns but may also overfit.\n",
    "\n",
    "**subsample**: Fraction of samples to be used for fitting the individual base learners; prevents overfitting by introducing more randomness into the model.\n",
    "\n",
    "**colsample_bytree**: Fraction of features (columns) to be used for each tree; similar to subsample, it adds randomness to the model, aiding in preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d0f9c-7fb0-4520-97ff-03eaa5e0cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_child_weight': [1, 2, 3, 4],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "# Initialize GridSearchCV and fit to find the best parameters\n",
    "grid_search = GridSearchCV(xgb, param_grid, scoring='accuracy', cv=5, verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "# Print best parameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f0bb0-fc93-4750-9465-c1df71a45dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-train the model with the best parameters on the full training set\n",
    "xgb_optimized = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_optimized.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_optimized = xgb_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Calculate and print the accuracy on the test set\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(\"Test set accuracy with optimized parameters: {:.2f}%\".format(accuracy_optimized * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8204db0-c397-458e-b02a-a6d372e48461",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4762e-a58d-4ef3-8166-01c52bd2c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and plot feature importances from the model\n",
    "importances = xgb.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure()\n",
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], color='r', align='center')\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad1cd5-251f-4826-b9eb-730603a11bf5",
   "metadata": {},
   "source": [
    "### Model with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fa4cf-034c-4c78-a037-3edb2c162783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the average cross-validation scores for different numbers of top features\n",
    "cv_scores = []\n",
    "\n",
    "# Iterate over the range of number of features, starting from 1 to the total number of features\n",
    "for i in range(1, len(indices) + 1):\n",
    "    # Select the top 'i' features\n",
    "    top_features = [X_train.columns[indices[j]] for j in range(i)]\n",
    "    \n",
    "    # Create the training data using the selected features\n",
    "    X_train_top = X_train_scaled[:, indices[:i]]\n",
    "    \n",
    "    # Initialize the model with the best parameters\n",
    "    model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    \n",
    "    # Perform cross-validation and store the mean score\n",
    "    scores = cross_val_score(model, X_train_top, y_train, cv=5, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Find the number of features that resulted in the highest mean CV score\n",
    "optimal_features = np.argmax(cv_scores) + 1  # Adding 1 because list indices start at 0\n",
    "optimal_score = cv_scores[optimal_features - 1]\n",
    "\n",
    "print(f\"Optimal number of features: {optimal_features}\")\n",
    "print(f\"Highest CV accuracy: {optimal_score:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd1e15-38cb-4bb9-93f0-c4e0c97f1394",
   "metadata": {},
   "source": [
    "### #plot the CV scores as a function of the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb6247-9d5f-4b57-867a-838fb5f1a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(indices) + 1), cv_scores, marker='o')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('CV Accuracy')\n",
    "plt.title('CV Performance vs. Number of Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479bbd05-4fae-446d-b408-354928a6f1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top 'optimal_features' features based on their importance rankings\n",
    "top_features_indices = indices[:optimal_features]\n",
    "X_train_optimal = X_train_scaled[:, top_features_indices]\n",
    "X_test_optimal = X_test_scaled[:, top_features_indices]\n",
    "\n",
    "# Train the model using the selected subset of features\n",
    "model_optimal = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_optimal.fit(X_train_optimal, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred_optimal = model_optimal.predict(X_test_optimal)\n",
    "accuracy_optimal = accuracy_score(y_test, y_pred_optimal)\n",
    "\n",
    "print(f\"Test set accuracy with optimal number of features ({optimal_features}): {accuracy_optimal:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da3e57-8478-434e-8770-4d52583d2d72",
   "metadata": {},
   "source": [
    "### Trying to select features manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec2267-cd21-4d2e-8ac2-b4f6507d1d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model using only the top 10 features\n",
    "top_features = [X_train.columns[i] for i in indices[:10]]\n",
    "X_train_top = scaler.fit_transform(X_train[top_features])\n",
    "X_test_top = scaler.transform(X_test[top_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc88155-a487-44cc-b1b7-b7ba8427b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the XGBoost classifier with best parameters and selected features\n",
    "xgb_top = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_top.fit(X_train_top, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4aef35-ebe1-43ba-9948-6e46657717f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and evaluate the model\n",
    "y_pred_top = xgb_top.predict(X_test_top)\n",
    "accuracy_top = accuracy_score(y_test, y_pred_top)\n",
    "print(\"Accuracy with top 10 features:\", accuracy_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c1b0e-6857-4b47-bf0d-e7c9d3009aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011d4f4-4a62-4804-85e1-01b384f7869a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
